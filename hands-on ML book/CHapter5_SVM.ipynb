{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM Classification\n",
    "<br>\n",
    "<img src=\"../img/large_mrg_cls.png\" alt=\"Large Margin Classification\" style=\"width: 500px;\"/> <br>\n",
    "Both these images are can be seperated by a line (linearly seperable). The left plot shows the deciswion boundaries of three possible linear classifiers. The model whose decisioun boundary is seperated by the dashed line is so bad that ist does not even seperate the classes properly. The other two models work perfectly on the training set. but their decision boundairies come so close to the instances that these models will probably not perform as well on new instances. <br><br>\n",
    "Large margin classification - fitting the widest possible street (represented by the parallel dashed lines) between the classes. <br><br>\n",
    "Support Vectors - adding more training instances \"off the street\" will not affect the decision boundary at all: it is fully determined (or \"supported\") by the instances located on the edge of the street. These are called Support Bectors (they are circles in the image above).<br> <br>\n",
    "<img src=\"../img/sensitivity_to_feat_scale.png\" alt=\"Sensitivity to feature scaling\" style=\"width: 500px;\"/> <br> \n",
    "SVMs are sensitive to to the feature scales. the vertical scale is much larger than the horizontal scale, so the widest possible street is close to hoizontal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Margin Classification\n",
    "hard margin classification - If we strictly impose that all instances must be off the street and on the right side, this is called hard margin classification. <br>\n",
    "Hard margin has 2 main issues: first, it only wirks if the data is linearly seperable, second, it is sensitive to outliers. See image below to see issue with hard margin.<br>\n",
    "<img src=\"../img/hard_margin_sens.png\" alt=\"Hard Margin Sensitivity\" style=\"width: 500px;\"/> <br>\n",
    "To avoid these issues, use a more flexible model. The objective is to find a good balance between keeping the street as large as possible and limiting the margin violations. This is called soft margin classification.<br>\n",
    "<br>\n",
    "When creating a SVM model using ScikitLearn, you can specify a number of hyperparameters. C is one of those hyperparameters. If youur SVM model is overfitting, you can try regularizing it by reducing C. If w eset it to a low value, then we end up with the model on the left. With a high value, we get the model on the right. Margin violations are bad. It's usually better to have few of them. However, in this case the model on the left has a lot of margin violations but will probably generalize better.<br>\n",
    "<img src=\"../img/c_hyperparameter.png\" alt=\"Reducing C Hyperparamert\" style=\"width: 500px;\"/><br> "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "362f10d2c1a231c17ac246becce2545daa81640b66c74881ccf242998023883a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
