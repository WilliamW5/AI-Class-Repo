{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (ANNs)\n",
    "Simulated using ANNs to perform various logical computations using propositional logic.<br>\n",
    "<img src=\"../img/anns_logic_computations.png\" alt=\"ANNs performing simple logical computations\" style=\"width: 500px;\"/><br>\n",
    "## Perceptron\n",
    "One of the simplest ANN architectures. It is based on another artificial neuron called a threshold logic unit (TLU), sometimes called a linear threshold unit (LTU): The inputs and outputs are row numbers (instead of binary on/off values) and each input connection is associated with a weight. The TLU computes a weighted sum of its inputs (z= w_1x_1 + w_2x_2 + ... + w_nx_n = x^Tw) then applies a step function to that sum and outputs the result h_w(x) = step(z), where z = x_tw. <br>\n",
    "<img src=\"../img/threshold_unit.png\" alt=\"Threshold Logic Unit\" style=\"width: 500px;\"/><br>\n",
    "The most common step function used in Perceptrons is the Heaviside step function. <br>\n",
    "<img src=\"../img/common_step_functions.png\" alt=\"Common Step Functions used in Perceptrons\" style=\"width: 500px;\"/><br>\n",
    "A Perceptron is composed of a single layer of TLUs, with each TLU connected to all the inputs. <br>\n",
    "When all neurons in single layer are connected to every neuron in the previous layer (i.e, its input neurons), it is called a **fully connected layer** or a **dense layer**.<br>\n",
    "A Percepton with two inputs and three outputs is represented below. This Perceptron can classify instances simultaneously into three different binary classes, which make it a multi-output classifer.<br>\n",
    "<img src=\"../img/perceptron_diagram.png\" alt=\"Perceptron with two inputs and three outputs\" style=\"width: 500px;\"/><br>\n",
    "<img src=\"../img/computing_output.png\" alt=\"Computing outputs of a fulyl connected layer\" style=\"width: 500px;\"/><br>\n",
    "<br>\n",
    "\"Cells that fire together, wire together\" Siegrid Lowel\n",
    "Also known as Hebb's rule (or Hebbian Learning). That is, the connection weight between two neurons is increased whenever they have the same output. <br>\n",
    "The Perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct predictions.<br>\n",
    "<img src=\"../img/perceptron_learning_rule.png\" alt=\"Perceptron learning rule (weight update)\" style=\"width: 500px;\"/><br>\n",
    "<br>\n",
    "The decision boundary of each output neuron is linear, so Perceptroms are incapable of learning complex patterns(just like Logistic Regression Classifers). However, if the training instances are linearly seperable, Rosenblatt demonstrated that this algorithm would converge to a solution. This is called the **Perceptron Convergence theorem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\William\\AppData\\Local\\Temp\\ipykernel_11040\\905234873.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris.target == 0).astype(np.int) # Iris Setosa?\n"
     ]
    }
   ],
   "source": [
    "# Scikit-Learn provides a Perceptron class that implements a single TLU network.\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limitations of Perceptrons can be eliminated by stacking multiple Perceptrons. The resulting ANN is call a multi-layer Perceptron (MLP). In particular, an MLP can solve the XOR problem, as you can verify by computing the output of the MLP represented on the right of the figure below: with inputs (0, 0) or (1, 1) the network outputs 0, and with the inputs (0, 1) ir (1, 0) it outputs 1. All connections have weight equal to 1, except the four connections where the weight is shown. This network indeed solves the XOR problem! <br>\n",
    "<img src=\"../img/mlp_xor_problem.png\" alt=\"XOR classification problem and an MLP that solves it\" style=\"width: 500px;\"/><br>\n",
    "<br>\n",
    "### Multi-layer Perceptron and Backpropagation\n",
    "An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer. The layers close to the input layers are usually called the **lower layers** and the ones closer to the output are called the **upper layers**. Every layer except the output layer includes a bias neuron and is fully connected to the next layer.<br>\n",
    "<img src=\"../img/mlp.png\" alt=\"Multi-Layer Perceptron\" style=\"width: 500px;\"/><br>\n",
    "<br>\n",
    "When an ANN contains a deep stack of hidden layers, it is called a deep neural network (DNN). Researchers struggled with training MLPs. When David Rumelhart, Geoffrey Hinton, and Ronald WIlliams introduced backpropagation training algorithm which is, in short, Gradient Descent using an efficient technique for computing the gradients automatically: in just two passes through the network (one forward, one backward), the backpropagation algorithm is able to compute the gradient of the netwrok's error with regards to every single model parameter. In other words, it can find out how each connection weight and each bias term should be tweaked in order to reduce the error. <br>\n",
    "Summarizing the algorith again: for each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building an Image classifier \n",
    "# Using Keras to load a dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a validation set\n",
    "# Since we are working with Gradient Descent, we must scale the input features\n",
    "# For simplicity, we scale the pixel intensity down to the 0-1 range by dividing\n",
    "# them by 255.0 (also converts them to float)\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Neural Network\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of the code above\n",
    "model = keras.models.Sequential()\n",
    "- Creates a Sequential model.\n",
    "- This is the simplest kind of model, for neural networks that are just composed of a single stack of layers, connected sequentiall.\n",
    "- This is called the sequential API\n",
    "<br>\n",
    "#\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "- Builds the first layer and add it to the model\n",
    "- It is a Flatten layer whose role is simply to convert each input image into a 1D array: if it received input data X, it computes X.reshape(-1,1).\n",
    "- This layer does not have any parameters, it is just there to do simple preprocessing.\n",
    "- Since it's the first layer of the model, you should specify the **input_shape**: this does not include the batch size, only the shape of the instances.\n",
    "- Alternatively, you could add a keras.layers.InputLayer as the first layer, setting shape=[28,28]\n",
    "<br>\n",
    "#\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "- Next, we add a Dense hidden layer with 300 neurons. It will use the ReLU activation function.\n",
    "- Each Dense layer manages its own weight matrix, containing all the connection weights between the neurons and their inputs. \n",
    "- Also manages a vector of bias terms (one per neuron).\n",
    "- When it receives some input data, it computes:<br>\n",
    "<img src=\"../img/computing_output.png\" alt=\"Computing outputs of a fulyl connected layer\" style=\"width: 500px;\"/><br>\n",
    "#\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "- Next we add a second dense hidden layer with 100 neurons, also using the ReLU activation function.<br>\n",
    "#\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "- Finally, we add a Dense output layer with 10 neurons (one per class), using the softmax activation function (because the classes are exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of adding the layers one by one, we could do:\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x12b1cc28580>,\n",
       " <keras.layers.core.dense.Dense at 0x12b1cc28820>,\n",
       " <keras.layers.core.dense.Dense at 0x12b1cc220d0>,\n",
       " <keras.layers.core.dense.Dense at 0x12b01fbc9d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain model's list of layers\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch a layer by it's index\n",
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch a layer by it's name\n",
    "model.get_layer('dense_3').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05263013, -0.03770253, -0.00352375, ..., -0.01688108,\n",
       "         0.06511584, -0.02911106],\n",
       "       [ 0.03732178, -0.0337542 ,  0.04668865, ...,  0.07274641,\n",
       "         0.06863692,  0.0481708 ],\n",
       "       [-0.06217652, -0.01679416,  0.00659889, ...,  0.05089553,\n",
       "        -0.06837372,  0.06263876],\n",
       "       ...,\n",
       "       [ 0.05098173,  0.07139263, -0.05148792, ...,  0.04269697,\n",
       "         0.00914418,  0.01109549],\n",
       "       [-0.05238184, -0.05849144,  0.05433187, ..., -0.01371299,\n",
       "        -0.03166789, -0.04849031],\n",
       "       [-0.00114647,  0.01543771, -0.00833649, ..., -0.04973795,\n",
       "        -0.04986561,  0.05984688]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All parameters of a layer can be accessed using its get_weights() and set_weights() method\n",
    "hidden1 = model.layers[1] #hidden1.name   will output 'dense'\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After a model is created, you must call it's compile() method to specify\n",
    "# the loss function and the optimizer to use. Also can specify a list of extra\n",
    "# metrics to compute during training and evaluation\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.7389 - accuracy: 0.7596 - val_loss: 0.5175 - val_accuracy: 0.8302\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4927 - accuracy: 0.8292 - val_loss: 0.4549 - val_accuracy: 0.8484\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4450 - accuracy: 0.8447 - val_loss: 0.4596 - val_accuracy: 0.8422\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4170 - accuracy: 0.8531 - val_loss: 0.4038 - val_accuracy: 0.8636\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3970 - accuracy: 0.8610 - val_loss: 0.3878 - val_accuracy: 0.8648\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3806 - accuracy: 0.8662 - val_loss: 0.3792 - val_accuracy: 0.8708\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3663 - accuracy: 0.8710 - val_loss: 0.3997 - val_accuracy: 0.8590\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3551 - accuracy: 0.8745 - val_loss: 0.3536 - val_accuracy: 0.8754\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3457 - accuracy: 0.8769 - val_loss: 0.3562 - val_accuracy: 0.8744\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3365 - accuracy: 0.8805 - val_loss: 0.3409 - val_accuracy: 0.8776\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3287 - accuracy: 0.8828 - val_loss: 0.3314 - val_accuracy: 0.8830\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3192 - accuracy: 0.8867 - val_loss: 0.3295 - val_accuracy: 0.8864\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3131 - accuracy: 0.8878 - val_loss: 0.3276 - val_accuracy: 0.8798\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3065 - accuracy: 0.8899 - val_loss: 0.3224 - val_accuracy: 0.8832\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2988 - accuracy: 0.8931 - val_loss: 0.3374 - val_accuracy: 0.8788\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2939 - accuracy: 0.8941 - val_loss: 0.3252 - val_accuracy: 0.8824\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2876 - accuracy: 0.8965 - val_loss: 0.3440 - val_accuracy: 0.8752\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2813 - accuracy: 0.8992 - val_loss: 0.3221 - val_accuracy: 0.8848\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2764 - accuracy: 0.9008 - val_loss: 0.3168 - val_accuracy: 0.8862\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2714 - accuracy: 0.9017 - val_loss: 0.3068 - val_accuracy: 0.8908\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2662 - accuracy: 0.9047 - val_loss: 0.2982 - val_accuracy: 0.8866\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2616 - accuracy: 0.9059 - val_loss: 0.3018 - val_accuracy: 0.8910\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2566 - accuracy: 0.9065 - val_loss: 0.3049 - val_accuracy: 0.8854\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2518 - accuracy: 0.9082 - val_loss: 0.3211 - val_accuracy: 0.8830\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2475 - accuracy: 0.9098 - val_loss: 0.3107 - val_accuracy: 0.8886\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2435 - accuracy: 0.9126 - val_loss: 0.3115 - val_accuracy: 0.8840\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2388 - accuracy: 0.9131 - val_loss: 0.2963 - val_accuracy: 0.8912\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2345 - accuracy: 0.9156 - val_loss: 0.2917 - val_accuracy: 0.8932\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2309 - accuracy: 0.9167 - val_loss: 0.3174 - val_accuracy: 0.8884\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2264 - accuracy: 0.9185 - val_loss: 0.2937 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per last epoch\n",
    "We can see the validation is 89%\n",
    "<br><br>\n",
    "### Epochs\n",
    "in terms of ANNs, an epoch refers to one cycle through the full training dataset. Usually training a neural network takes more than a few epochs. In other words, if we feed a neural network the training data for more than one epoch in different patters, we hope for a better generalization when given a new 'unseen' input(test set). Epochs are often mixed up with an iteration. Iterations is the number of batches or steps through partitioned packets of the training data, needed to complete one epoch.<br>\n",
    "https://deepai.org/machine-learning-glossary-and-terms/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the bertical range from [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that both the training and validation accuracy steadily increase during training, while the training and validation loss decrease. Good! Moreover, the validation curbes are quite close to the training curves, which means that there is not too much overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 57.5352 - accuracy: 0.8532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[57.535186767578125, 0.8532000184059143]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once satisfied with the accuracy, you can use evaluate() method to evaluate the on the test set to estimate the generalization error before deploying\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the model to make predictions\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulding a Regression MLP using the Sequential API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target\n",
    ")\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valud_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: nan - val_loss: nan\n",
      "162/162 [==============================] - 0s 738us/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Main difference is that the output layer has a single neuron, since we only want to predict a single value\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:3] #pretend these are new instances\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building complex models using the functional API\n",
    "\n",
    "an example of a non-sequential neural network is a **Wide and Deep** neural network. It connects all or part of the inputs directly to the output layer. <br>\n",
    "<img src=\"../img/wide_and_deep.png\" alt=\"Wide and Deep Neural Network\" style=\"width: 500px;\"/><br>\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2741c62eeb6d3c2dbd0c707b9d4df7ca82c89a9cca53ee8435971b6b6816686"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
